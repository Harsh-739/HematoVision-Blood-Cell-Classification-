# -*- coding: utf-8 -*-
"""Blood_cell_Classification-1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UsyV1zu8pxj_LllHecFDYyD4zJfSCSUL

#Importing the libraries
"""

import os
import pandas as pd
import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt
import seaborn as sns

#import cv2
from tensorflow.keras.models import load_model
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator


#Define the directory path
data_dir="/Users/harshpreet/Desktop/Blood_cell_classification/archive 2/dataset2-master/dataset2-master/images/TRAIN"

#Define the class labels
class_labels=[ 'EOSINOPHIL', 'MONOCYTE', 'LYMPHOCYTE', 'NEUTROPHIL']

#Initialize lists to hold file paths and labels
filepaths=[]
labels=[]


#Loop through each class directory and gather file paths and labels
for label in class_labels:
  class_dir=os.path.join(data_dir, label)
  for file in os.listdir(class_dir):
    if file.endswith('jpeg') or file.endswith('.png'):    #Ensure file is an image
      filepaths.append(os.path.join(class_dir, file))
      labels.append(label)

#Create a DataFrame from the file paths and labels
bloodCell_df=pd.DataFrame({
    'filepaths':filepaths,
    'labels':labels
})

#Shuffle the DataFrame
bloodCell_df=bloodCell_df.sample(frac=1).reset_index(drop=True)

bloodCell_df.head()

"""#Split Data"""

train_images, test_images=train_test_split(bloodCell_df,test_size=0.3, random_state=42)
train_set, val_set=train_test_split(bloodCell_df, test_size=0.2,random_state=42)

print(train_set.shape)

print(test_images.shape)

print(val_set.shape)

print(train_images.shape)

image_gen=ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input)
train=image_gen.flow_from_dataframe(dataframe=train_set,x_col="filepaths",y_col="labels",
                                    target_size=(244,244),
                                    color_mode='rgb',
                                    class_mode="categorical",
                                    batch_size=8,
                                    shuffle=False
                                    )
test=image_gen.flow_from_dataframe(dataframe=test_images,x_col="filepaths",y_col="labels",
                                    target_size=(244,244),
                                    color_mode='rgb',
                                    class_mode="categorical",
                                    batch_size=8,
                                    shuffle=False
                                    )
val=image_gen.flow_from_dataframe(dataframe=val_set,x_col="filepaths",y_col="labels",
                                    target_size=(244,244),
                                    color_mode='rgb',
                                    class_mode="categorical",
                                    batch_size=8,
                                    shuffle=False
                                    )

"""#Visualisation"""

import matplotlib.pyplot as plt
import numpy as np
def show_knee_images(image_gen):
  test_dict=test.class_indices
  classes=list(test_dict.keys())
  images, labels=next(image_gen)
  plt.figure(figsize=(20,20))


  length=len(labels)
  if length<25:
    r=length
  else:
    r=25


  for i in range(r):
    plt.subplot(5,5,i+1)
    image=(images[i]+1)/2
    plt.imshow(image)
    index=np.argmax(labels[i])
    class_name=classes[index]
    plt.title(class_name, color="green", fontsize=16)
    plt.axis('off')
  plt.show()
show_knee_images(train)

"""#Model Building"""

model=keras.models.Sequential([
    keras.layers.Conv2D(filters=128,kernel_size=(8,8),strides=(3,3),activation='relu',input_shape=(224,224,3)),
    keras.layers.BatchNormalization(),

    keras.layers.Conv2D(filters=256, kernel_size=(5,5),strides=(1,1),activation='relu',padding="same"),
    keras.layers.BatchNormalization(),
    keras.layers.MaxPool2D(pool_size=(3,3)),

    keras.layers.Conv2D(filters=256, kernel_size=(3,3),strides=(1,1),activation='relu',padding="same"),
    keras.layers.BatchNormalization(),
    keras.layers.Conv2D(filters=256, kernel_size=(1,1),strides=(1,1),activation='relu',padding="same"),
    keras.layers.BatchNormalization(),
    keras.layers.Conv2D(filters=256, kernel_size=(1,1),strides=(1,1),activation='relu',padding="same"),
    keras.layers.BatchNormalization(),


    keras.layers.Conv2D(filters=512, kernel_size=(3,3),activation='relu',padding="same"),
    keras.layers.BatchNormalization(),
    keras.layers.MaxPool2D(pool_size=(2,2)),

    keras.layers.Conv2D(filters=512, kernel_size=(3,3),activation='relu',padding="same"),
    keras.layers.BatchNormalization(),

    keras.layers.Conv2D(filters=512, kernel_size=(3,3),activation='relu',padding="same"),
    keras.layers.BatchNormalization(),
    keras.layers.MaxPool2D(pool_size=(2,2)),

    keras.layers.Conv2D(filters=512, kernel_size=(3,3),activation='relu',padding="same"),
    keras.layers.BatchNormalization(),
    keras.layers.MaxPool2D(pool_size=(2,2)),

    keras.layers.Flatten(),
    keras.layers.Dense(1024,activation='relu'),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(1024,activation='relu'),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(4,activation='softmax'),

])

model.compile(
    loss='categorical_crossentropy',
    optimizer=tf.optimizers.SGD(learning_rate=0.001),
    metrics=['accuracy']
)

model.summary()

history=model.fit(train, epochs=5,validation_data=val, verbose=1)
history1=model.fit(train, epochs=1,validation_data=val, verbose=1)


#Testing Model and Data Prediction
pred=model.predict(test)
pred=np.argmax(pred, axis=1)

labels=(train.class_indices)
labels=dict((v,k) for k,v in labels.items())
pred2=[labels[k] for k in pred]


plt.plot(history.history['accuracy']+history1.history['accuracy'])
plt.plot(history.history['val_accuracy']+history1.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train','val'],loc='upper left')
plt.show()

plt.plot(history.history['loss']+history1.history['loss'])
plt.plot(history.history['val_loss']+history1.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train','val'],loc='upper left')
plt.show()



from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.metrics import classification_report

y_test=test_images.labels
print(classification_report(y_test, pred2))
print("Accuracy of  the model: ","{:.1f}%".format(accuracy_score(y_test,pred2)*100))




class_labels=[ 'EOSINOPHIL', 'MONOCYTE', 'LYMPHOCYTE', 'NEUTROPHIL']
cm=confusion_matrix(y_test, pred2)
plt.figure(figsize=(10,7))
sns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='Blues')
plt.xticks(ticks=[0.5,1.5,2.5,3.5], labels=class_labels)
plt.yticks(ticks=[0.5,1.5,2.5,3.5], labels=class_labels)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()


model.save("Blood Cell.h5")




